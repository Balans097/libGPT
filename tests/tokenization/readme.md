# ДОКУМЕНТАЦИЯ ПО ТЕСТАМ БИБЛИОТЕКИ ТОКЕНИЗАЦИИ

## Обзор

Комплексный набор тестов для проверки всех функций библиотеки токенизации v0.5.
Включает 8 групп тестов с общим числом 80+ индивидуальных проверок.

## Структура тестов

### ГРУППА 1: ТЕСТЫ BPE (14 тестов)
Проверка базового алгоритма Byte Pair Encoding:
- ✓ Размер словаря и корректность создания
- ✓ Специальные токены (PAD, UNK, BOS, EOS)
- ✓ Токенизация и декодирование
- ✓ Согласованность vocab и inverseVocab
- ✓ Наличие и корректность BPE merges
- ✓ Сохранение и загрузка токенизатора
- ✓ Идентичность после загрузки
- ✓ Вычисление метрик

### ГРУППА 2: ТЕСТЫ WORDPIECE (10 тестов)
Проверка алгоритма WordPiece (используется в BERT):
- ✓ Тип токенизатора
- ✓ Размер словаря
- ✓ Префикс продолжения подслова (##)
- ✓ Специальные токены
- ✓ Токенизация с префиксами
- ✓ Декодирование (удаление ## префиксов)
- ✓ Обработка неизвестных слов
- ✓ Разбиение длинных слов
- ✓ Согласованность encode-decode
- ✓ Метрики утилизации словаря

### ГРУППА 3: ТЕСТЫ SENTENCEPIECE (10 тестов)
Проверка алгоритма SentencePiece (используется в T5, XLNet):
- ✓ Тип токенизатора
- ✓ Размер словаря
- ✓ Наличие scores для токенов
- ✓ Специальные токены
- ✓ Токенизация и декодирование
- ✓ Все токены имеют scores
- ✓ Обработка пробелов
- ✓ Консистентность encode-decode
- ✓ Метрики коэффициента сжатия

### ГРУППА 4: ТЕСТЫ BYTE-LEVEL BPE (12 тестов)
Проверка Byte-Level BPE (GPT-2/GPT-3 style):
- ✓ Тип токенизатора
- ✓ Byte encoder (256 символов)
- ✓ Byte decoder (256 символов)
- ✓ Консистентность encoder/decoder
- ✓ Токенизация UTF-8 текста
- ✓ Точное декодирование (без потери данных)
- ✓ Обработка специальных символов
- ✓ Обработка чисел
- ✓ Сохранение пробелов
- ✓ Генерация token offsets
- ✓ Корректность char offsets
- ✓ Корректность byte offsets

### ГРУППА 5: ТЕСТЫ ДОПОЛНИТЕЛЬНЫХ ФУНКЦИЙ (20 тестов)
Проверка вспомогательных функций библиотеки:
- ✓ cleanText (HTML, URLs, email, пробелы)
- ✓ encodeBatch (батч-обработка)
- ✓ encodeWithPadding (паддинг до заданной длины)
- ✓ maskTokens (маскирование для MLM)
- ✓ getSubwordBreakdown (разбиение на подслова)
- ✓ estimateTokenCount (оценка без токенизации)
- ✓ validateTokenizer (валидация)
- ✓ compareTokenizers (сравнение)
- ✓ analyzeVocabulary (анализ словаря)
- ✓ pruneVocabulary (уменьшение словаря)
- ✓ toLowerUnicode / toUpperUnicode (регистр)

### ГРУППА 6: ТЕСТЫ КЭШИРОВАНИЯ И ПРОИЗВОДИТЕЛЬНОСТИ (8 тестов)
Проверка оптимизаций:
- ✓ Кэш изначально пуст
- ✓ Cache miss при первой токенизации
- ✓ Cache hit при повторной токенизации
- ✓ Кэш содержит элементы
- ✓ Ускорение при использовании кэша
- ✓ Очистка кэша
- ✓ Batch processing производительность
- ✓ Метрики скорости токенизации

### ГРУППА 7: ТЕСТЫ BPE-DROPOUT И РЕГУЛЯРИЗАЦИИ (8 тестов)
Проверка subword regularization:
- ✓ Оригинальная токенизация
- ✓ Dropout с вероятностью 0.0
- ✓ Вариативность токенизации
- ✓ Dropout с minDropped
- ✓ Детерминированность при одинаковом seed
- ✓ Декодирование dropout токенов
- ✓ Сохранение смысла текста

### ГРУППА 8: ТЕСТЫ СПЕЦИАЛЬНЫХ СЛУЧАЕВ (10 тестов)
Проверка граничных случаев:
- ✓ Пустая строка
- ✓ Строка из пробелов
- ✓ Очень длинная строка (1000+ слов)
- ✓ Односимвольная строка
- ✓ Только цифры
- ✓ Только спецсимволы
- ✓ Смешанные языки (кириллица + латиница)
- ✓ Unicode emoji
- ✓ Повторяющиеся символы
- ✓ Декодирование пустой последовательности

## Статистический анализ

После выполнения всех тестов генерируется подробный отчёт:

### Таблица результатов по группам
```
┌──────────────────────────────────────────────────────────────────────┐
│ ГРУППА                              │ ПРОЙДЕНО │ ПРОВАЛЕНО │ ВРЕМЯ  │
├──────────────────────────────────────────────────────────────────────┤
│ ГРУППА 1: ТЕСТЫ BPE                 │ 14/14    │ 0         │ X.XXXs │
│ ГРУППА 2: ТЕСТЫ WORDPIECE           │ 10/10    │ 0         │ X.XXXs │
│ ...                                 │          │           │        │
└──────────────────────────────────────────────────────────────────────┘
```

### Общая статистика
- Всего тестов
- Успешно пройдено (%)
- Провалено
- Общее время выполнения
- Среднее время на тест

### Анализ производительности
- Самая быстрая группа тестов
- Самая медленная группа тестов
- Среднее время выполнения

## Сравнительный анализ токенизаторов

Дополнительный раздел, сравнивающий все 4 типа токенизаторов:

### Сравнение токенизации
Показывает, как каждый токенизатор разбивает тестовый текст

### Сравнение метрик
```
                    │   BPE   │ WordPiece │ SentPiece │ ByteLvlBPE
────────────────────┼─────────┼───────────┼───────────┼───────────
Размер словаря      │   XXX   │    XXX    │    XXX    │    XXX
Коэфф. сжатия       │  X.XX   │   X.XX    │   X.XX    │   X.XX
Утилиз. словаря     │  XX.X%  │   XX.X%   │   XX.X%   │   XX.X%
UNK токенов         │  XX.X%  │   XX.X%   │   XX.X%   │   XX.X%
```

### Проверка декодирования
Показывает результаты декодирования для каждого токенизатора

## Использование

### Запуск основного файла с встроенными тестами:
```bash
nim c -r tokenization.nim
```

### Запуск отдельного файла тестов:
```bash
nim c -r tokenization_tests_standalone.nim
```

### Компиляция с оптимизацией:
```bash
nim c -d:release tokenization.nim
nim c -d:release -d:danger --opt:speed tokenization.nim
```

## Тестовые данные

### Корпус для обучения
10 тестовых предложений на русском языке, покрывающих различные аспекты:
- Общие фразы
- Технические термины (NLP, ML, нейронные сети)
- Популярные модели (BERT, GPT, трансформеры)

### Тестовые предложения
8 специализированных предложений для проверки:
- Простые и сложные предложения
- Специальные символы
- Цифры
- Смешанный регистр
- Повторяющиеся слова
- Реальные примеры текста

## Выходной формат

Тесты выводят:
- ✓ для успешных тестов (зелёная галочка)
- ✗ для проваленных тестов (красный крест)
- Подробные сообщения об ошибках
- Статистику по времени выполнения

## Примечания

- Все тексты и сообщения выводятся на русском языке
- Тесты используют встроенный корпус (не требуют внешних файлов)
- Каждая группа тестов независима
- Временные файлы автоматически удаляются
- Поддерживается детерминированное воспроизведение результатов

## Зависимости

Требуется только базовая библиотека токенизации (tokenization.nim).
Все тестовые утилиты встроены в main секцию.




