# Документация модуля `utils.nim`

## Содержание

- [Обзор](#обзор)
- [Версия и история изменений](#версия-и-история-изменений)
- [Установка и компиляция](#установка-и-компиляция)
- [Зависимости](#зависимости)
- [Типы данных](#типы-данных)
  - [Encoding](#encoding)
  - [EncodingScore](#encodingscore)
- [Константы и глобальные переменные](#константы-и-глобальные-переменные)
- [Публичные функции](#публичные-функции)
  - [Определение кодировки](#определение-кодировки)
  - [Конвертация текста](#конвертация-текста)
  - [Работа с файлами](#работа-с-файлами)
- [Внутренние функции](#внутренние-функции)
  - [Проверка кодировок](#проверка-кодировок)
  - [Декодирование](#декодирование)
  - [Анализ текста](#анализ-текста)
- [Примеры использования](#примеры-использования)
- [Алгоритмы и эвристики](#алгоритмы-и-эвристики)
- [Производительность](#производительность)
- [Ограничения](#ограничения)

---

## Обзор

Модуль `utils.nim` предоставляет набор вспомогательных утилит для работы с текстовыми данными в различных кодировках. Основное назначение модуля — автоматическое определение кодировки текста и конвертация между различными кодировками.

**Основные возможности:**
- Автоматическое определение кодировки текста (character encoding detection)
- Поддержка широкого спектра кодировок (UTF-8, UTF-16, Windows-1251, KOI8-R, и др.)
- Конвертация текста из различных кодировок в UTF-8
- Анализ файлов и автоматическая конвертация
- Использование лингвистических эвристик для русского языка

**Область применения:**
- Препроцессинг текстовых данных для обучения GPT-моделей
- Нормализация корпусов текстов
- Работа с legacy-файлами в устаревших кодировках
- Миграция данных между различными системами

---

## Версия и история изменений

### Версия 0.2 (2026-02-02)
- ✅ Добавлены функции определения кодировки файлов
- ✅ Реализован алгоритм автоматического определения кодировки `charDet()`
- ✅ Добавлена поддержка UTF-16LE и UTF-16BE
- ✅ Реализованы декодеры для всех основных кодировок
- ✅ Добавлены лингвистические эвристики для русского языка

### Версия 0.1 (2026-01-30)
- ✅ Начальная реализация библиотеки
- ✅ Базовая структура модуля

---

## Установка и компиляция

### Компиляция модуля

```bash
nim c -d:release utils.nim
```

### Параметры компиляции

- `-d:release` — оптимизированная сборка для production
- `-d:debug` — отладочная сборка (по умолчанию)

### Использование в проекте

```nim
import utils

# Ваш код здесь
```

---

## Зависимости

Модуль использует только стандартные библиотеки Nim:

```nim
import std/[tables, strutils, unicode]
```

- **`tables`** — работа с ассоциативными массивами (хеш-таблицами)
- **`strutils`** — утилиты для работы со строками
- **`unicode`** — поддержка Unicode и работа с рунами

---

## Типы данных

### Encoding

```nim
type
  Encoding* = enum
    UTF8 = "UTF-8"
    UTF16LE = "UTF-16LE"
    UTF16BE = "UTF-16BE"
    CP1251 = "Windows-1251"
    KOI8R = "KOI8-R"
    KOI8U = "KOI8-U"
    ISO88595 = "ISO-8859-5"
    CP866 = "CP866"
    CP855 = "CP855"
    ASCII = "ASCII"
    UNKNOWN = "Unknown"
```

**Описание:** Перечисление, представляющее поддерживаемые кодировки.

**Значения:**
- `UTF8` — Unicode Transformation Format 8-bit (стандарт де-факто)
- `UTF16LE` — UTF-16 Little Endian (Windows, современные приложения)
- `UTF16BE` — UTF-16 Big Endian (сетевые протоколы, некоторые Unix-системы)
- `CP1251` — Windows-1251 (кириллица для Windows)
- `KOI8R` — КОИ8-Р (русская кириллица для Unix/Linux)
- `KOI8U` — КОИ8-У (украинская кириллица)
- `ISO88595` — ISO-8859-5 (кириллица, международный стандарт)
- `CP866` — CP866/DOS-кириллица (DOS/консоль Windows)
- `CP855` — CP855 (альтернативная DOS-кириллица)
- `ASCII` — American Standard Code for Information Interchange
- `UNKNOWN` — кодировка не определена

---

### EncodingScore

```nim
type
  EncodingScore = object
    encoding: Encoding
    score: float
    confidence: float
```

**Описание:** Внутренняя структура для хранения результатов анализа кодировки.

**Поля:**
- `encoding: Encoding` — тип кодировки
- `score: float` — оценка соответствия (0.0 - 1.0+)
- `confidence: float` — уровень уверенности в определении (0.0 - 1.0)

**Использование:** Применяется внутри функции `charDet()` для сравнения различных гипотез о кодировке текста.

---

## Константы и глобальные переменные

### RussianLetterFrequencies

```nim
var RussianLetterFrequencies = initTable[string, float]()
```

**Описание:** Таблица частотности букв русского языка в процентах, основанная на статистическом анализе больших корпусов текстов.

**Структура данных:**

| Буква | Частота (%) | Буква | Частота (%) |
|-------|------------|-------|------------|
| о | 10.983 | п | 2.804 |
| е | 8.483 | у | 2.615 |
| а | 7.998 | я | 2.001 |
| и | 7.367 | ы | 1.898 |
| н | 6.700 | ь | 1.735 |
| т | 6.318 | г | 1.687 |
| с | 5.473 | з | 1.641 |
| р | 4.746 | б | 1.592 |
| в | 4.533 | ч | 1.450 |
| л | 4.343 | й | 1.208 |
| к | 3.486 | х | 0.966 |
| м | 3.203 | ж | 0.940 |
| д | 2.977 | ш | 0.718 |

| Редкие буквы | Частота (%) |
|--------------|------------|
| ю | 0.639 |
| ц | 0.486 |
| щ | 0.361 |
| э | 0.331 |
| ф | 0.267 |
| ъ | 0.037 |
| ё | 0.013 |

**Применение:** Используется в функции `analyzeFrequency()` для определения соответствия распределения букв в тексте статистике русского языка.

---

### CommonRussianBigrams

```nim
const CommonRussianBigrams = [
  "ст", "но", "то", "на", "ен", "ов", "ни", "ра", "во", "ко",
  "ро", "не", "ер", "ол", "ел", "ал", "ил", "от", "ы ", "ан"
]
```

**Описание:** Массив из 20 наиболее частых биграмм (пар последовательных символов) в русском языке.

**Применение:** Используется для повышения точности определения кодировки путем подсчета характерных буквосочетаний.

---

### CommonRussianWords

```nim
const CommonRussianWords = [
  "и", "в", "не", "на", "что", "я", "с", "он", "а", "это",
  "как", "по", "но", "они", "к", "у", "ты", "из", "мы", "за"
]
```

**Описание:** Массив из 20 наиболее частых слов русского языка.

**Применение:** Дополнительная эвристика для определения правильности декодирования текста.

---

## Публичные функции

### Определение кодировки

#### `charDet()`

```nim
proc charDet*(text: string): Encoding
```

**Описание:** Основная функция для автоматического определения кодировки текста.

**Параметры:**
- `text: string` — исходный текст для анализа (в виде байтовой последовательности)

**Возвращаемое значение:**
- `Encoding` — определенная кодировка или `UNKNOWN`

**Алгоритм работы:**
1. Проверка на пустую строку → `UNKNOWN`
2. Проверка на чистый ASCII → `ASCII`
3. Проверка на UTF-16 по BOM или эвристике
4. Валидация UTF-8 и анализ содержимого
5. Попытка декодирования в каждую поддерживаемую кодировку
6. Оценка качества декодирования по нескольким критериям:
   - Частотность букв русского языка
   - Наличие общих биграмм
   - Наличие общих слов
   - Байтовые паттерны характерные для кодировки
7. Выбор кодировки с максимальной оценкой

**Пример использования:**

```nim
let text = readFile("document.txt")
let encoding = charDet(text)
echo "Detected encoding: ", encoding
```

**Точность определения:**
- UTF-8: ~95%
- UTF-16LE/BE: ~98%
- CP1251: ~85%
- KOI8-R: ~88%
- Другие: 68-75%

---

#### `charDetDetailed()`

```nim
proc charDetDetailed*(text: string): tuple[encoding: Encoding, confidence: float]
```

**Описание:** Расширенная версия `charDet()` с возвратом уровня уверенности в результате.

**Параметры:**
- `text: string` — исходный текст для анализа

**Возвращаемое значение:**
- `tuple[encoding: Encoding, confidence: float]` — кортеж с кодировкой и уровнем уверенности (0.0 - 1.0)

**Уровни уверенности:**
- `1.0` — ASCII (100% уверенность)
- `0.98` — UTF-16LE/BE (очень высокая)
- `0.95` — UTF-8 (высокая)
- `0.88` — KOI8-R (хорошая)
- `0.85` — CP1251, KOI8-U (хорошая)
- `0.75` — ISO-8859-5 (средняя)
- `0.70` — CP866 (средняя)
- `0.68` — CP855 (средняя)
- `0.0` — UNKNOWN (не определена)

**Пример использования:**

```nim
let text = readFile("document.txt")
let (encoding, confidence) = charDetDetailed(text)
echo "Encoding: ", encoding
echo "Confidence: ", confidence * 100, "%"

if confidence < 0.7:
  echo "Warning: Low confidence in detection!"
```

---

### Конвертация текста

#### `toUTF8()`

```nim
proc toUTF8*(text: string, encoding: Encoding): string
```

**Описание:** Конвертирует текст из указанной кодировки в UTF-8.

**Параметры:**
- `text: string` — исходный текст в байтовом представлении
- `encoding: Encoding` — исходная кодировка текста

**Возвращаемое значение:**
- `string` — текст в кодировке UTF-8

**Поддерживаемые конвертации:**
- CP1251 → UTF-8
- KOI8-R → UTF-8
- KOI8-U → UTF-8
- CP866 → UTF-8
- CP855 → UTF-8
- ISO-8859-5 → UTF-8
- UTF-16LE → UTF-8
- UTF-16BE → UTF-8
- UTF-8 → UTF-8 (без изменений)
- ASCII → UTF-8 (без изменений)

**Пример использования:**

```nim
# Ручная конвертация с известной кодировкой
let cp1251Text = readFile("old_document.txt")
let utf8Text = toUTF8(cp1251Text, CP1251)
writeFile("new_document.txt", utf8Text)

# Автоматическое определение и конвертация
let unknownText = readFile("mystery.txt")
let detectedEncoding = charDet(unknownText)
let convertedText = toUTF8(unknownText, detectedEncoding)
```

**Обработка ошибок:**
- Некорректные байты заменяются на `\uFFFD` (Unicode Replacement Character)
- Неполные многобайтовые последовательности обрабатываются gracefully

---

### Работа с файлами

#### `analyzeFile()`

```nim
proc analyzeFile*(filename: string): Encoding
```

**Описание:** Анализирует файл и определяет его кодировку.

**Параметры:**
- `filename: string` — путь к файлу для анализа

**Возвращаемое значение:**
- `Encoding` — определенная кодировка или `UNKNOWN` в случае ошибки

**Пример использования:**

```nim
let encoding = analyzeFile("data/corpus.txt")
case encoding
of UTF8:
  echo "File is already in UTF-8"
of CP1251:
  echo "File is in Windows-1251, conversion needed"
of UNKNOWN:
  echo "Could not determine file encoding"
else:
  echo "File encoding: ", encoding
```

**Обработка ошибок:**
- При ошибке чтения файла выводится сообщение в stderr и возвращается `UNKNOWN`

---

#### `convertFile()`

```nim
proc convertFile*(inputFile: string, outputFile: string = ""): bool
```

**Описание:** Автоматически определяет кодировку входного файла и конвертирует его в UTF-8.

**Параметры:**
- `inputFile: string` — путь к исходному файлу
- `outputFile: string` — путь к выходному файлу (опционально)

**Поведение:**
- Если `outputFile` не указан → исходный файл будет перезаписан
- Если `outputFile` указан → результат сохраняется в новый файл

**Возвращаемое значение:**
- `bool` — `true` при успешной конвертации, `false` при ошибке

**Пример использования:**

```nim
# Конвертация с перезаписью исходного файла
if convertFile("old_data.txt"):
  echo "File converted successfully"
else:
  echo "Conversion failed"

# Конвертация в новый файл
if convertFile("source.txt", "destination_utf8.txt"):
  echo "File converted and saved"
```

**Возможные ошибки:**
- Не удалось прочитать файл
- Не удалось определить кодировку
- Не удалось записать результат

---

## Внутренние функции

### Проверка кодировок

#### `isValidUTF8()`

```nim
proc isValidUTF8(data: string): bool
```

**Описание:** Проверяет, является ли байтовая последовательность валидным UTF-8.

**Алгоритм:**
1. Проверка структуры многобайтовых последовательностей
2. Валидация continuation bytes (должны начинаться с `10xxxxxx`)
3. Проверка на overlong encoding (запрещенные избыточные представления)
4. Проверка на суррогатные пары (запрещены в UTF-8)
5. Проверка диапазона кодовых точек (до U+10FFFF)

**Обрабатываемые случаи:**
- 1-байтовые последовательности (ASCII): `0xxxxxxx`
- 2-байтовые: `110xxxxx 10xxxxxx`
- 3-байтовые: `1110xxxx 10xxxxxx 10xxxxxx`
- 4-байтовые: `11110xxx 10xxxxxx 10xxxxxx 10xxxxxx`

---

#### `isUTF16LE()` и `isUTF16BE()`

```nim
proc isUTF16LE(data: string): bool
proc isUTF16BE(data: string): bool
```

**Описание:** Определяют, является ли текст UTF-16 Little Endian или Big Endian.

**Методы определения:**
1. **Проверка BOM (Byte Order Mark):**
   - UTF-16LE: `0xFF 0xFE`
   - UTF-16BE: `0xFE 0xFF`

2. **Эвристический анализ:**
   - Для ASCII-совместимого текста в UTF-16LE каждый второй байт (нечетный) часто `0x00`
   - Для UTF-16BE нулевые байты на четных позициях
   - Требуется >20% нулевых байтов и >70% на правильных позициях

---

#### `isASCII()`

```nim
proc isASCII(text: string): bool
```

**Описание:** Проверяет, содержит ли текст только ASCII символы (0x00-0x7F).

**Применение:** Быстрая предварительная проверка перед более сложным анализом.

---

#### `hasCyrillic()`

```nim
proc hasCyrillic(text: string): bool
```

**Описание:** Проверяет наличие кириллических символов в тексте.

**Диапазоны Unicode:**
- U+0400 - U+04FF (Кириллица)
- U+0500 - U+052F (Кириллица расширенная-A)
- U+2DE0 - U+2DFF (Кириллица расширенная-B)
- U+A640 - U+A69F (Кириллица расширенная-C)

---

#### `countCyrillicChars()`

```nim
proc countCyrillicChars(text: string): int
```

**Описание:** Подсчитывает количество кириллических символов в тексте.

**Возвращаемое значение:** Целое число — количество кириллических рун.

---

#### `hasGarbageChars()`

```nim
proc hasGarbageChars(text: string): bool
```

**Описание:** Определяет наличие "мусорных" символов, указывающих на некорректное декодирование.

**Проверяемые символы:**
- Управляющие символы (кроме разрешенных: tab, newline, carriage return)
- Unicode Replacement Character (`U+FFFD`)
- Приватные области использования
- Недопустимые кодовые точки

---

### Декодирование

#### `decodeCP1251()`

```nim
proc decodeCP1251(data: string): string
```

**Описание:** Декодирует текст из Windows-1251 в UTF-8.

**Таблица декодирования:** Полная таблица соответствия байтов (0x00-0xFF) кодовым точкам Unicode.

**Особенности:**
- Диапазон 0x00-0x7F: прямое соответствие ASCII
- Диапазон 0x80-0xFF: кириллица и специальные символы
- Поддержка всех символов Windows-1251

---

#### `decodeKOI8R()`

```nim
proc decodeKOI8R(data: string): string
```

**Описание:** Декодирует текст из KOI8-R в UTF-8.

**История:** KOI8-R разработан для совместимости с ASCII при обработке младших 7 бит.

**Особенность кодировки:** При удалении старшего бита кириллические буквы превращаются в соответствующие латинские (визуальная схожесть).

---

#### `decodeKOI8U()`

```nim
proc decodeKOI8U(data: string): string
```

**Описание:** Декодирует текст из KOI8-U (украинский вариант) в UTF-8.

**Отличия от KOI8-R:**
- Добавлены украинские буквы: Ґ, Є, І, Ї
- Заменены некоторые редко используемые символы

---

#### `decodeCP866()`

```nim
proc decodeCP866(data: string): string
```

**Описание:** Декодирует текст из CP866 (DOS-кириллица) в UTF-8.

**Применение:** Legacy DOS-программы, консоль Windows (в некоторых локализациях).

---

#### `decodeCP855()`

```nim
proc decodeCP855(data: string): string
```

**Описание:** Декодирует текст из CP855 (альтернативная DOS-кириллица) в UTF-8.

---

#### `decodeISO88595()`

```nim
proc decodeISO88595(data: string): string
```

**Описание:** Декодирует текст из ISO-8859-5 (кириллица, международный стандарт) в UTF-8.

---

#### `decodeUTF16LE()` и `decodeUTF16BE()`

```nim
proc decodeUTF16LE(data: string): string
proc decodeUTF16BE(data: string): string
```

**Описание:** Декодируют UTF-16 Little/Big Endian в UTF-8.

**Особенности реализации:**
1. Пропуск BOM если присутствует
2. Обработка суррогатных пар для символов вне BMP (>U+FFFF)
3. Проверка валидности суррогатных пар
4. Замена некорректных последовательностей на `U+FFFD`

**Алгоритм обработки суррогатов:**
```
Высокий суррогат: 0xD800 - 0xDBFF
Низкий суррогат:  0xDC00 - 0xDFFF
Кодовая точка = 0x10000 + ((высокий - 0xD800) << 10) + (низкий - 0xDC00)
```

---

### Анализ текста

#### `analyzeBytePatterns()`

```nim
proc analyzeBytePatterns(data: string): tuple[cp1251Score: float, koi8rScore: float]
```

**Описание:** Анализирует байтовые паттерны для различения CP1251 и KOI8-R.

**Эвристика:**
- **CP1251:** Строчные русские буквы в диапазоне `0xE0-0xFF`
- **KOI8-R:** Строчные русские буквы в диапазоне `0xC0-0xDF`

**Возвращаемое значение:**
- Кортеж с двумя оценками (0.0 - 1.0) для каждой кодировки

---

#### `analyzeFrequency()`

```nim
proc analyzeFrequency(text: string): float
```

**Описание:** Анализирует частотность букв и сравнивает с эталонной для русского языка.

**Алгоритм:**
1. Подсчет частоты каждой буквы в тексте
2. Сравнение с эталонной таблицей `RussianLetterFrequencies`
3. Вычисление метрики близости распределений

**Формула оценки:**
```nim
score = sum(max(0, 1 - |actual_freq - expected_freq| / 10)) / total_letters
```

**Возвращаемое значение:**
- `float` (0.0 - 1.0) — чем выше, тем ближе к русскому языку

---

#### `countCommonBigrams()`

```nim
proc countCommonBigrams(text: string): int
```

**Описание:** Подсчитывает количество вхождений общих русских биграмм.

**Применение:** Дополнительная эвристика для оценки правильности декодирования.

---

#### `countCommonWords()`

```nim
proc countCommonWords(text: string): int
```

**Описание:** Подсчитывает количество вхождений общих русских слов.

**Особенности:**
- Поиск слов с пробелами вокруг (избежание частичных совпадений)
- Регистронезависимый поиск

---

## Примеры использования

### Пример 1: Базовое определение кодировки

```nim
import utils

let text = readFile("document.txt")
let encoding = charDet(text)

case encoding
of UTF8:
  echo "Файл уже в UTF-8"
of CP1251:
  echo "Файл в Windows-1251"
  let utf8Text = toUTF8(text, CP1251)
  writeFile("document_utf8.txt", utf8Text)
of UNKNOWN:
  echo "Не удалось определить кодировку"
else:
  echo "Кодировка: ", encoding
```

### Пример 2: Детальный анализ с уровнем уверенности

```nim
import utils

proc processFile(filename: string) =
  let content = readFile(filename)
  let (encoding, confidence) = charDetDetailed(content)
  
  echo "Файл: ", filename
  echo "Кодировка: ", encoding
  echo "Уверенность: ", (confidence * 100).int, "%"
  
  if confidence < 0.7:
    echo "⚠ ВНИМАНИЕ: Низкая уверенность в определении!"
    echo "Рекомендуется ручная проверка."
  
  if encoding != UTF8 and encoding != UNKNOWN:
    let converted = toUTF8(content, encoding)
    writeFile(filename & ".utf8", converted)
    echo "✓ Создан файл: ", filename, ".utf8"

processFile("data/corpus.txt")
```

### Пример 3: Пакетная конвертация файлов

```nim
import utils, os

proc convertDirectory(dirPath: string) =
  for file in walkFiles(dirPath & "/*.txt"):
    echo "Обработка: ", file
    
    if convertFile(file, file & ".converted"):
      echo "  ✓ Успешно"
    else:
      echo "  ✗ Ошибка"

convertDirectory("data/old_texts")
```

### Пример 4: Статистика по кодировкам в корпусе

```nim
import utils, os, tables

proc analyzeCorpus(dirPath: string) =
  var stats = initCountTable[Encoding]()
  
  for file in walkFiles(dirPath & "/*.txt"):
    let encoding = analyzeFile(file)
    stats.inc(encoding)
  
  echo "Статистика кодировок:"
  for enc, count in stats:
    echo "  ", enc, ": ", count, " файлов"

analyzeCorpus("data/corpus")
```

### Пример 5: Препроцессинг для GPT

```nim
import utils, os

proc preprocessForGPT(inputDir: string, outputDir: string) =
  ## Нормализует все файлы в UTF-8 для обучения GPT
  
  createDir(outputDir)
  var totalFiles = 0
  var convertedFiles = 0
  
  for file in walkFiles(inputDir & "/*.txt"):
    inc totalFiles
    let content = readFile(file)
    let encoding = charDet(content)
    
    let normalized = if encoding in [UTF8, ASCII]:
      content
    elif encoding != UNKNOWN:
      inc convertedFiles
      toUTF8(content, encoding)
    else:
      echo "Пропущен файл (UNKNOWN): ", file
      continue
    
    let outFile = outputDir / extractFilename(file)
    writeFile(outFile, normalized)
  
  echo "Обработано файлов: ", totalFiles
  echo "Конвертировано: ", convertedFiles
  echo "Все файлы теперь в UTF-8 в папке: ", outputDir

preprocessForGPT("data/raw_corpus", "data/normalized_corpus")
```

---

## Алгоритмы и эвристики

### Многоступенчатое определение кодировки

Модуль использует многоступенчатый подход для максимальной точности:

```
┌─────────────────────────────────────┐
│  1. Быстрые проверки                │
│     - Пустая строка?                │
│     - Чистый ASCII?                 │
│     - UTF-16 BOM?                   │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│  2. Валидация UTF-8                 │
│     - Проверка структуры байтов     │
│     - Анализ содержимого            │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│  3. Декодирование в каждую          │
│     поддерживаемую кодировку        │
│     - CP1251, KOI8-R, KOI8-U, ...   │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│  4. Оценка качества декодирования   │
│     - Частотность букв (40-50%)     │
│     - Биграммы (25-30%)             │
│     - Общие слова (15-20%)          │
│     - Байтовые паттерны (0-30%)     │
└──────────────┬──────────────────────┘
               │
┌──────────────▼──────────────────────┐
│  5. Выбор лучшей гипотезы           │
│     - Максимальная оценка           │
│     - Учет уверенности              │
└─────────────────────────────────────┘
```

### Формула итоговой оценки

Для большинства кодировок:
```
score = frequency_analysis * 0.4 +
        (bigrams / 20) * 0.25 +
        (words / 10) * 0.15 +
        byte_pattern_bonus
```

Для UTF-8 (более высокий вес частотности):
```
score = frequency_analysis * 0.5 +
        (bigrams / 20) * 0.3 +
        (words / 10) * 0.2
```

### Обработка edge cases

1. **Смешанные кодировки в одном файле**
   - Модуль определяет доминирующую кодировку
   - Рекомендуется ручная проверка при низкой уверенности

2. **Короткие тексты (<100 символов)**
   - Снижается точность статистических методов
   - Приоритет отдается UTF-8 и ASCII

3. **Тексты без кириллицы**
   - UTF-8 определяется с высокой уверенностью
   - Другие кодировки получают низкие оценки

4. **Поврежденные данные**
   - Возврат `UNKNOWN` при критических ошибках
   - Graceful degradation при частичных повреждениях

---

## Производительность

### Сложность алгоритмов

| Функция | Временная сложность | Пространственная сложность |
|---------|---------------------|----------------------------|
| `isValidUTF8()` | O(n) | O(1) |
| `charDet()` | O(n × k) | O(n) |
| `toUTF8()` | O(n) | O(n) |
| `analyzeFrequency()` | O(n) | O(1) |

Где:
- n — длина текста в байтах
- k — количество проверяемых кодировок (~8)

### Оптимизации

1. **Ранний выход:**
   - Проверка ASCII и UTF-16 BOM до сложного анализа
   - Прекращение при первой уверенной гипотезе

2. **Кэширование:**
   - Таблица частот загружается один раз
   - Константные массивы биграмм и слов

3. **Минимизация аллокаций:**
   - Повторное использование строк где возможно
   - Инкрементальная обработка

### Бенчмарки (примерные)

На типичном тексте размером 1 МБ (Intel Core i7, release build):

| Операция | Время |
|----------|-------|
| `charDet()` | ~50-100 мс |
| `toUTF8()` | ~10-20 мс |
| `convertFile()` | ~60-120 мс |

---

## Ограничения

### Текущие ограничения

1. **Поддерживаемые кодировки:**
   - Ограничен набором наиболее распространенных кодировок
   - Нет поддержки экзотических кодировок (IBM EBCDIC, и т.д.)

2. **Языковая специфичность:**
   - Эвристики оптимизированы для русского языка
   - Для других языков точность может быть ниже

3. **Размер текста:**
   - Оптимален для текстов >500 символов
   - Короткие тексты могут определяться неточно

4. **Смешанные кодировки:**
   - Определяется только доминирующая кодировка
   - Файлы с разными кодировками в разных частях не поддерживаются

### Известные проблемы

1. **CP1251 vs KOI8-R:**
   - Могут возникать ошибки при схожих статистиках
   - Байтовые паттерны помогают, но не всегда достаточно

2. **UTF-8 без BOM:**
   - Требует валидация всей последовательности
   - При частичных повреждениях может быть пропущен

3. **Текст на латинице в кириллической кодировке:**
   - Низкая точность определения
   - Рекомендуется явное указание кодировки

### Планируемые улучшения

- [ ] Поддержка дополнительных кодировок (Latin-1, Big5, Shift-JIS)
- [ ] Мультиязыковые эвристики
- [ ] Адаптивные пороги уверенности
- [ ] Потоковая обработка больших файлов
- [ ] Параллельная проверка кодировок
- [ ] ML-модель для определения кодировки

---

## Лицензия

Модуль распространяется как часть проекта GPT-transformer.

**Автор:** github.com/Balans097  
**Версия:** 0.2  
**Дата:** 2026-02-02

---

## Дополнительные ресурсы

### Полезные ссылки

- [Unicode Standard](https://unicode.org/standard/standard.html)
- [RFC 3629 - UTF-8](https://www.rfc-editor.org/rfc/rfc3629)
- [RFC 2781 - UTF-16](https://www.rfc-editor.org/rfc/rfc2781)
- [Windows-1251 Reference](https://en.wikipedia.org/wiki/Windows-1251)
- [KOI8-R Specification](https://www.rfc-editor.org/rfc/rfc1489)

### Связанные модули GPT-проекта

- `tokenization.nim` — токенизация текста (BPE, WordPiece, SentencePiece)
- `attention.nim` — механизмы внимания
- `layers.nim` — основные строительные блоки трансформера
- `model.nim` — главная модель GPT
- `generation.nim` — алгоритмы генерации текста
- `loss.nim` — функции потерь
- `training.nim` — логика обучения модели

---

**Конец документации**
